<!DOCTYPE html>
<html lang="en" dir="ltr" prefix="content: http://purl.org/rss/1.0/modules/content/  dc: http://purl.org/dc/terms/  foaf: http://xmlns.com/foaf/0.1/  og: http://ogp.me/ns#  rdfs: http://www.w3.org/2000/01/rdf-schema#  schema: http://schema.org/  sioc: http://rdfs.org/sioc/ns#  sioct: http://rdfs.org/sioc/types#  skos: http://www.w3.org/2004/02/skos/core#  xsd: http://www.w3.org/2001/XMLSchema# ">
<head>
  <meta charset="utf-8" />
<link rel="shortlink" href="https://cyber.fsi.stanford.edu/io/node/21985" />
<link rel="canonical" href="https://cyber.fsi.stanford.edu/io/news/using-safety-design-address-online-harms" />
<meta property="og:type" content="news" />
<meta property="og:url" content="https://cyber.fsi.stanford.edu/io/news/using-safety-design-address-online-harms" />
<meta property="og:title" content="Using ‘safety by design’ to address online harms" />
<meta property="og:image" content="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/1200x630/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?itok=UeKTF7oQ" />
<meta property="og:image:url" content="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/1200x630/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?itok=UeKTF7oQ" />
<meta property="og:image:secure_url" content="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/1200x630/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?itok=UeKTF7oQ" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="Using ‘safety by design’ to address online harms" />
<meta name="twitter:description" content="A look at how user choice and transparency provide new ways of addressing content moderation and online safety policy." />
<meta name="twitter:creator" content="@FSIStanford" />
<meta name="twitter:image" content="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/1200x630/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?itok=UeKTF7oQ" />
<meta name="Generator" content="Drupal 10 (https://www.drupal.org)" />
<meta name="MobileOptimized" content="width" />
<meta name="HandheldFriendly" content="true" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="icon" href="/themes/custom/stanford_fsi/favicon.ico" type="image/vnd.microsoft.icon" />
<link rel="alternate" hreflang="en" href="https://cyber.fsi.stanford.edu/io/news/using-safety-design-address-online-harms" />
<link rel="apple-touch-icon" href="/themes/custom/stanford_fsi/apple-touch-icon.png" sizes="180x180" />
<link rel="icon" href="/themes/custom/stanford_fsi/favicon-32x32.png" type="image/png" sizes="32x32" />
<link rel="icon" href="/themes/custom/stanford_fsi/favicon-16x16.png" type="image/png" sizes="16x16" />

    <title>Using ‘safety by design’ to address online harms | FSI</title>
    <link rel="stylesheet" media="all" href="/sites/default/files/css/css_r5tCShwysLqDwgb6c8eJfUVgwMzR0tk8MpGRvuA2PyI.css?delta=0&amp;language=en&amp;theme=stanford_fsi&amp;include=eJxNyFsOwyAMRNENoXg5_YwMOOCGYGRDH7tvlKhNf0ZnblgpcheduUaq3RcJK_zZ2ds6beDRyFnHuojGeX8c4NgrLsaQingsLogSRB0Ny4R3fLmGikmxZfvmq0yjtuELW6boLKNSz2zwk3swPQ2OnTaJo5BLIqnQHIzg5K4bdtINdf0AowlTTA" />
<link rel="stylesheet" media="all" href="//use.fontawesome.com/releases/v5.15.4/css/all.css" />
<link rel="stylesheet" media="all" href="/sites/default/files/css/css_t4NLaHgNMYjDpnVUx0TC0ND4Ps914U85VZWqdnKZYGM.css?delta=2&amp;language=en&amp;theme=stanford_fsi&amp;include=eJxNyFsOwyAMRNENoXg5_YwMOOCGYGRDH7tvlKhNf0ZnblgpcheduUaq3RcJK_zZ2ds6beDRyFnHuojGeX8c4NgrLsaQingsLogSRB0Ny4R3fLmGikmxZfvmq0yjtuELW6boLKNSz2zwk3swPQ2OnTaJo5BLIqnQHIzg5K4bdtINdf0AowlTTA" />
<link rel="stylesheet" media="print" href="/sites/default/files/css/css_ipHMTqOd8MXWqrdkR7q2zw0hNkDpwEl3Km7uwx8BlwY.css?delta=3&amp;language=en&amp;theme=stanford_fsi&amp;include=eJxNyFsOwyAMRNENoXg5_YwMOOCGYGRDH7tvlKhNf0ZnblgpcheduUaq3RcJK_zZ2ds6beDRyFnHuojGeX8c4NgrLsaQingsLogSRB0Ny4R3fLmGikmxZfvmq0yjtuELW6boLKNSz2zwk3swPQ2OnTaJo5BLIqnQHIzg5K4bdtINdf0AowlTTA" />
<link rel="stylesheet" media="all" href="/themes/custom/stanford_fsi/fonts/fonts-drupal.css?sqgpes" />
<link rel="stylesheet" media="all" href="/sites/default/files/css/css_bcFdiuS3gduCe2D3ssVjb8Y-swJeW0X65YmoDTOZuq0.css?delta=5&amp;language=en&amp;theme=stanford_fsi&amp;include=eJxNyFsOwyAMRNENoXg5_YwMOOCGYGRDH7tvlKhNf0ZnblgpcheduUaq3RcJK_zZ2ds6beDRyFnHuojGeX8c4NgrLsaQingsLogSRB0Ny4R3fLmGikmxZfvmq0yjtuELW6boLKNSz2zwk3swPQ2OnTaJo5BLIqnQHIzg5K4bdtINdf0AowlTTA" />
<link rel="stylesheet" media="all" href="/themes/custom/stanford_fsi/no-aggregation/no-aggregation.css?sqgpes" />

      <script type="application/json" data-drupal-selector="drupal-settings-json">{"path":{"baseUrl":"\/","pathPrefix":"io\/","currentPath":"node\/21985","currentPathIsAdmin":false,"isFront":false,"currentLanguage":"en"},"pluralDelimiter":"\u0003","suppressDeprecationErrors":true,"gtm":{"tagId":null,"settings":{"data_layer":"dataLayer","include_classes":false,"allowlist_classes":"","blocklist_classes":"","include_environment":false,"environment_id":"","environment_token":""},"tagIds":["GTM-5PWBZTH"]},"gtag":{"tagId":"G-S82RDPFHSE","consentMode":false,"otherIds":["G-XNZW311XMN",""],"events":[],"additionalConfigInfo":[]},"ajaxPageState":{"libraries":"eJxdjtFuwyAMRX-IhM_ZY-QEF7wARrZpu78f7aR29OXq-FzZ8nFiIGPZqAastmc-Tv-PXWSOGbdD0f_hoC8wlALyag2ijyM-5xW-4T7L4hoIRIGW1AfpDfL6Nmuvre-ZNGFwmkDQEql_kVODemEJ2w5Kh3_mW16UPHRLLLqMIzY3MfMOeXYJIaAsxnG8OFcFa18KUJ21ntQqXD9kE7Kx_6OG5fEVuivhTf0z18KhZ_wFwPiOmQ","theme":"stanford_fsi","theme_token":null},"ajaxTrustedUrl":{"\/io\/search\/google":true},"stanford_basic":{"nav_dropdown_enabled":false},"sharethis":{"publisher":"dr-d1ddf05c-9188-6ea9-62e5-3d0928aed407","version":"5x","doNotCopy":true,"hashAddressBar":false,"doNotHash":true},"googlePSE":{"language":"en","displayWatermark":false},"user":{"uid":0,"permissionsHash":"16f9c77489b88ad14c88c5ea4772986419600c068c4f05b78d0914545a48cc0e"}}</script>
<script src="/core/assets/vendor/modernizr/modernizr.min.js?v=3.11.7"></script>
<script src="/sites/default/files/js/js_gHKIUnKFJH5AVa-Frjm64i7Y6OXPfu4rEdEqpw0ByzE.js?scope=header&amp;delta=1&amp;language=en&amp;theme=stanford_fsi&amp;include=eJxdjksOg0AMQy8EneN0iQyETMp8UBKqHr-oiErDJnq2pdjmKEvVeRhhMoXf7ewyF5PAqY5IHdfKiQYHB_bcSvBdP_DCp7MIJY9i4U_tb-weq1qfxLxNbFNxar1ImEl7r3xUtVGmsvcZUq4hk1E48aAnnDRD11vHKlvB-ws1DGU2"></script>
<script src="/modules/contrib/google_tag/js/gtm.js?sqgpes"></script>
<script src="/modules/contrib/google_tag/js/gtag.js?sqgpes"></script>
<script src="/sites/default/files/js/js_uVtraW--ht-FY2xwXMRi2vx8JhZAfbd34kzTZ8lamq8.js?scope=header&amp;delta=4&amp;language=en&amp;theme=stanford_fsi&amp;include=eJxdjksOg0AMQy8EneN0iQyETMp8UBKqHr-oiErDJnq2pdjmKEvVeRhhMoXf7ewyF5PAqY5IHdfKiQYHB_bcSvBdP_DCp7MIJY9i4U_tb-weq1qfxLxNbFNxar1ImEl7r3xUtVGmsvcZUq4hk1E48aAnnDRD11vHKlvB-ws1DGU2"></script>

        </head>
<body class="page-news-using-safety-design-address-online-harms section-news path-node page-node-type-news subdomain domain--cyber page-body">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5PWBZTH"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<nav id="skipnav" class="skipnav">
  <div class="container">
    <ul>
              <li><a href="#main-content" class="visually-hidden focusable skip-link">Skip to main content</a></li>
              <li><a href="#main-nav" class="visually-hidden focusable skip-link">Skip to main navigation</a></li>
          </ul>
  </div>
</nav>
  <div class="dialog-off-canvas-main-canvas" data-off-canvas-main-canvas>
    





<div  class="layout-container">
  <header  class="header">
                  <div  class="header-top header-top--cyber region region-top-header-left bg-red z-[10]">
    <div class="container">
              <div  id="block-header-top" class="block block-content ced1bdcf-a613-4da6-ae1e-cd14a7af31d2">
  
    
      

            <div class="block-content basic body text-with-summary label-hidden text-long"><p><span><a href="http://www.stanford.edu/">Stanford University</a></span></p></div>
      
  </div>

          </div>
  </div>

    
                      <div  class="header-main header-main--cyber region region-header relative z-[11] bg-white">
    <div class="container relative flex z-1">
      <div class="
        flex flex-col w-full
        1024:flex-row 1024:items-center
      ">
                  <div  id="block-fsi-domain-logo" class="block fsi-domain-logo">
  
    
      <div class="subdomain-logo__left py-5">
      
              <a href="/io" title="Home" rel="home" class="hidden 1024:block">
          <img src="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/2022-09/internet-observatory-web_-_tara_c_wright.jpg" alt="IO Logo"/>
        </a>
      
              <a href="/io" title="Home" rel="home" class="1024:hidden">
          <img src="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/2022-09/internet-observatory-web_-_tara_c_wright.jpg" alt="IO Logo"/>
        </a>
          </div>
</div>
<div  id="block-fsi-subdomain-logo" class="block fsi-subdomain-logo">
  
    
        <div class="subdomain-logo__right">
      <p>A program of the&nbsp;<a href="https://cyber.fsi.stanford.edu/">Cyber Policy Center</a>, a joint initiative of the&nbsp;<a href="http://fsi.stanford.edu/">Freeman Spogli Institute for International Studies</a> and <a href="https://law.stanford.edu/">Stanford Law School</a>.</p>

    </div>
  </div>

              </div>
    </div>
  </div>

          
            
<button class="toggle-expand" arial-live="polite">
  <span class="toggle-expand__open">
    


<svg  class="toggle-expand__icon"

  
  
  >
      <use xlink:href="/themes/custom/stanford_fsi/dist/icons.svg#menu"></use>
</svg>
    <span
      class="toggle-expand__text"
      aria-label="Open menu"
    >Menu</span>
  </span>
  <span class="toggle-expand__close">
    <span
      class="toggle-expand__text"
      aria-label="Close menu"
    >Close</span>
  </span>
</button>
    <div  class="header-navigation region region-navigation bg-red nav-collapsible">
    <div class="container relative">
              
<div class="search-block-form google-cse search-form-block block block-search container-inline" data-drupal-selector="search-block-form" id="block-stanford-fsi-search-header" role="search">
  
      <span class="visually-hidden">Search</span>
    
      <form action="/io/search/google" method="get" id="search-block-form" accept-charset="UTF-8">
  
    
<div class="js-form-item form-item form-item-edit-keys">
              <input title="Enter the terms you wish to search for." placeholder="Search Internet Observatory" data-drupal-selector="edit-keys" type="search" id="edit-keys" name="keys" value="" size="40" maxlength="128" class="form-search form-item__textfield" />
        </div>
<div id="edit-actions-search-block-form" data-drupal-selector="edit-actions" class="form-actions js-form-wrapper form-wrapper"><input data-drupal-selector="edit-submit" type="submit" id="edit-submit" value="Search" class="button js-form-submit form-submit form-item__textfield" />
</div>

</form>

  </div>
<div  id="block-fsi-main-menu" class="block fsi-main-menu main-menu-1803982">
  
    
      
<nav id="main-nav" class="main-nav bg-red">
  


    
                          
    
<ul  class="main-menu hidden">
            
<li  class="main-menu__item">
                <a href="/io" class="main-menu__link" data-drupal-link-system-path="&lt;front&gt;">Home</a>
          </li>
          
<li  class="main-menu__item main-menu__item--with-sub">
                <a href="/io/sio-research" class="main-menu__link main-menu__link--with-sub" data-drupal-link-system-path="node/34845">Research</a>
              <button class="expand-sub">
        <span class="expand-sub--opened">close menu</span>
        <span class="expand-sub--closed">open menu</span>
      </button>
          
                                    
    
<ul  class="main-menu main-menu--sub main-menu--sub-1 hidden">
            
<li  class="main-menu__item main-menu__item--sub main-menu__item--sub-1">
                <a href="/io/publications" class="main-menu__link main-menu__link--sub main-menu__link--sub-1" data-drupal-link-system-path="node/30781">Publications</a>
          </li>
      </ul>
  
      </li>
          
<li  class="main-menu__item main-menu__item--with-sub">
                <a href="/io/trust-safety" class="main-menu__link main-menu__link--with-sub" data-drupal-link-system-path="node/30233">Trust and Safety</a>
              <button class="expand-sub">
        <span class="expand-sub--opened">close menu</span>
        <span class="expand-sub--closed">open menu</span>
      </button>
          
                                    
    
<ul  class="main-menu main-menu--sub main-menu--sub-1 hidden">
            
<li  class="main-menu__item main-menu__item--sub main-menu__item--sub-1">
                <a href="https://tsjournal.org" target="_blank" class="main-menu__link main-menu__link--sub main-menu__link--sub-1">Journal of Online Trust and Safety</a>
          </li>
          
<li  class="main-menu__item main-menu__item--sub main-menu__item--sub-1">
                <a href="https://conferences.law.stanford.edu/tsrc/" target="_blank" class="main-menu__link main-menu__link--sub main-menu__link--sub-1">Trust &amp; Safety Research Conference </a>
          </li>
          
<li  class="main-menu__item main-menu__item--sub main-menu__item--sub-1">
                <a href="https://stanfordio.github.io/TeachingTrustSafety/" target="_blank" class="main-menu__link main-menu__link--sub main-menu__link--sub-1">Trust &amp; Safety Teaching Consortium</a>
          </li>
      </ul>
  
      </li>
          
<li  class="main-menu__item">
                <a href="/io/teaching" class="main-menu__link" data-drupal-link-system-path="node/30593">Teaching</a>
          </li>
          
<li  class="main-menu__item main-menu__item--with-sub">
                <a href="/io/about" class="main-menu__link main-menu__link--with-sub" data-drupal-link-system-path="node/29991">About</a>
              <button class="expand-sub">
        <span class="expand-sub--opened">close menu</span>
        <span class="expand-sub--closed">open menu</span>
      </button>
          
                                    
    
<ul  class="main-menu main-menu--sub main-menu--sub-1 hidden">
            
<li  class="main-menu__item main-menu__item--sub main-menu__item--sub-1">
                <a href="/io/content/opportunities" class="main-menu__link main-menu__link--sub main-menu__link--sub-1" data-drupal-link-system-path="node/30044">Opportunities</a>
          </li>
      </ul>
  
      </li>
      </ul>
  
</nav>

  </div>

          </div>
  </div>

    
          <div  id="block-views-block-alert-block-alert" class="block views-element-container views-block alert-block-alert">
  
    
      <div><div class="view alert block-alert js-view-dom-id-2fa4c2e6d33107fbac5269baee54678e7a89319515fe31170d9d9ca129e8c560">
  
  
  

  
  
  

    

  
  

  
  
</div>
</div>

  </div>


    
        </header>
      
    
    
    
    <div  class="main">
    <a id="main-content" tabindex="-1"></a>        
      <main role="main"  class="main-content">
        

  <div class="region region--content grid-full layout--pass--content-medium ie11-autorow" id="content">
    <div data-drupal-messages-fallback class="hidden"></div>
<div  id="block-stanford-fsi-content" class="block system-main-block">
  
    
      
<article about="/io/news/using-safety-design-address-online-harms" class="node node--type-news node--view-mode-full">
  <div class="node__content">
    

<h1
   about="/io/news/using-safety-design-address-online-harms" class="h visually-hidden h1 node node--type-news node--view-mode-full"
><div class="node news title string label-hidden">Using ‘safety by design’ to address online harms</div>
</h1>

          

<div  class="header-news pt-5 pb-10 768:pt-[70px] 768:pb-7.5">
  <div  class="header-news__container container container--smaller border-t-1 border-t-gray-e3 border-b-5 border-b-red py-5 768:pt-7 768:pb-8" >
          
  <nav  class="breadcrumb mb-[11px]" role='navigation' aria-labelledby='system-breadcrumb'>
    <h2  class="visually-hidden" id='system-breadcrumb'>Breadcrumb</h2>
    <ol  class="breadcrumb__list mb-[11px]">
                                          <li  class="breadcrumb__item font-bold">
                  <a  class="breadcrumb__link" href="http://cyber.fsi.stanford.edu/io/news">All Internet Observatory News</a>
              </li>
                                          <li  class="breadcrumb__item text-red">
                  Blogs
              </li>
                            <li  class="breadcrumb__item">
                  <time datetime="2022-07-26T12:00:00Z">July 26, 2022</time>

              </li>
        </ol>
  </nav>
    
                      <div  class="header-news__excerpt mb-7 link--in-article" >
              <h1 class="mb-3.5">
          <div class="node news title string label-hidden">Using ‘safety by design’ to address online harms</div>

                  </h1>
                              A look at how user choice and transparency provide new ways of addressing content moderation and online safety policy. 


                        </div>
    <div  class="header-news__annotation flex flex-wrap items-center" >
              
<div  class="bar-author-date bar-author-date--has-authors flex flex-wrap 480m:justify-center 480m:w-full">
      



<div  class="authors-list flex flex-wrap">
  <ul  class="authors-list__list flex flex-wrap 480m:justify-center mb-2.5">
          
      
      <li  class="authors-list__item inline-flex">
                              <a  class="authors-list__link" href="/io/people/john-perrino">
              John Perrino</a>      </li>
      </ul>
  </div>
  
  </div>
                  <div  class="header-news__social flex flex-wrap 480:ml-auto 480m:justify-center 480m:w-full" >
                          <div class="sharethis-wrapper">
      <span st_url="https://cyber.fsi.stanford.edu/io/news/using-safety-design-address-online-harms" st_title="Using ‘safety by design’ to address online harms" class="st_facebook_custom" displayText="facebook"></span>

      <span st_url="https://cyber.fsi.stanford.edu/io/news/using-safety-design-address-online-harms" st_title="Using ‘safety by design’ to address online harms" class="st_twitter_custom" displayText="twitter"></span>

      <span st_url="https://cyber.fsi.stanford.edu/io/news/using-safety-design-address-online-harms" st_title="Using ‘safety by design’ to address online harms" class="st_linkedin_custom" displayText="linkedin"></span>

      <span st_url="https://cyber.fsi.stanford.edu/io/news/using-safety-design-address-online-harms" st_title="Using ‘safety by design’ to address online harms" class="st_email_custom" displayText="email"></span>

  </div>

              </div>
    </div>
  </div>
</div>
    
    
    
            <div class="node news field-hero-image entity-reference label-hidden">


<div  class="image-caption max-w-[935px] container-side-styles">
      
<figure
   class="figure"
  >
      

  
<picture
   loading="eager" class="image"
>
          <!--[if IE 9]><video style="display: none;"><![endif]-->
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/895x498/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?h=3be70bd4&amp;itok=p4fgoSxf 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/895x498_x2/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?h=3be70bd4&amp;itok=KtSjuqM4 2x" media="all and (min-width: 768px)" type="image/png" width="895" height="498"/>
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?h=3be70bd4&amp;itok=gXDj-NY3 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409_x2/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?h=3be70bd4&amp;itok=q9BH1HVf 2x" media="all and (max-width: 767px)" type="image/png" width="727" height="409"/>
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/440x245/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?h=3be70bd4&amp;itok=qmvCYdCk 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/440x245_x2/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?h=3be70bd4&amp;itok=TdWWPMZi 2x" media="all and (max-width: 480px)" type="image/png" width="440" height="245"/>
        <!--[if IE 9]></video><![endif]-->
      
<img
   class="image"
      src="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/895x498/public/image-caption/screen_shot_2022-07-28_at_3.55.03_pm.png?h=3be70bd4&amp;itok=p4fgoSxf"
      alt="Advocates from Girlguiding U.K. unveil a badge urging an end to online harms ahead of meeting in London with members of Parliament to discuss the Online Safety Bill on Feb. 9, 2022."
    />
</picture>


            <em>Advocates from Girlguiding U.K. unveil a badge urging an end to online harms ahead of meeting in London with members of Parliament to discuss the Online Safety Bill on Feb. 9, 2022.<br />
</em>
    
          <strong></strong>
      </figure>

  </div>
</div>
      
    
      <div class="node news field-paragraphs entity-reference-revisions label-hidden">
              <div class="paragraph-item ptype-full-html">

<div class="full-html">
  <div  class="pgph_text container container--small text-20 leading-7.5 py-4 1024:py-5 full-html" >
  

            <div class="paragraph full-html field-formatted-text text-long label-hidden"><p><em>This piece originally appeared in <a href="https://www.brookings.edu/techstream/using-safety-by-design-to-address-online-harms/">Brookings TechStream</a>.</em></p>
</div>
      
</div>
</div>
</div>
              <div class="paragraph-item ptype-full-html">

<div class="full-html">
    <div  class="pgph_text pgph_text--big-character container container--small text-20 leading-7.5 py-4 1024:py-5 full-html" >
  

            <div class="paragraph full-html field-formatted-text text-long label-hidden"><p data-widget="core/paragraph">Around the world, policymakers are grappling with how to address the spread of harmful content and abuse online. From misinformation, to child sexual abuse material (CSAM), to harassment, and the promotion of self-harm, the range of issues on policymakers’ plates are diverse. All of them have real consequences in the lives of their constituents—and lack easy remedies.&nbsp;&nbsp;</p>

<p data-widget="core/paragraph">Recent rulemaking and legislative initiatives, however, have seen a shift in how policymakers are holding social media companies accountable for the well-being of their users. From the United States to Europe, lawmakers are increasingly embracing the principles of “<a href="https://www.esafety.gov.au/industry/safety-by-design/principles-and-background" rel="noreferrer noopener" target="_blank">safety by design</a>,” which aim to place accountability, user empowerment, and transparency at the heart of rules for online life.&nbsp;&nbsp;&nbsp;&nbsp;</p>

<p data-widget="core/paragraph">Safety by design offers a more proactive approach for policymakers to address ever-evolving online safety issues, even as these principles raise a new set of challenges. By embracing safety by design, policymakers can provide users with greater choice and understanding of how their online experiences are structured, granting users greater autonomy in mitigating online harms. But safety by design approaches also require careful balancing to preserve civil liberties and to ensure that they provide protections for all online users, not just the children whose safety concerns have come to dominate debates about how to regulate online life. Similarly, such rules need to be crafted in a way that provides consistent guidance for industry while offering a framework that is broad enough to be applied to future online social spaces—from live chat and video applications to the metaverse and beyond.&nbsp;</p>

<h2 data-widget="core/heading">Safety by design and in practice&nbsp;</h2>

<p data-widget="core/paragraph">Safety by design builds on the concept of “choice architecture” coined by the behavioral economists Richard Thaler and Cass Sunstein in their 2008 book&nbsp;<a href="https://www.penguinrandomhouse.com/books/690485/nudge-by-richard-h-thaler-and-cass-r-sunstein/" rel="noreferrer noopener" target="_blank"><em>Nudge</em></a>, which describes how the daily choices we make are shaped by how they are presented to us. Social media platforms have notoriously applied this concept to their product design to build applications that keep users engaged regardless of the benefits or harms of their experience—design choices that are often referred to as&nbsp;<a href="https://www.vox.com/recode/22351108/dark-patterns-ui-web-design-privacy" rel="noreferrer noopener" target="_blank">dark patterns</a>. Policymakers are increasingly engaging with this literature on behavioral science to understand online harms, as when the United Kingdom’s Competition and Markets Authority cited the work of Thaler, Sunstein, and other leading behavioral economists such as Daniel Kahneman and Amos Tversky in&nbsp;<a href="https://www.gov.uk/government/publications/online-choice-architecture-how-digital-design-can-harm-competition-and-consumers" rel="noreferrer noopener" target="_blank">a pair of reports</a>&nbsp;examining online choice architecture earlier this year.&nbsp;&nbsp;</p>

<p data-widget="core/paragraph">In its attempt to put user safety at the heart of technical systems, safety by design extends foundational concepts in online privacy and security—especially “privacy by design.”&nbsp;<a href="https://iapp.org/media/pdf/resource_center/pbd_implement_7found_principles.pdf" rel="noreferrer noopener" target="_blank">Privacy by design</a>&nbsp;was developed by the scholar Ann Cavoukian, who worked to integrate this concept into government regulation while serving as the information and privacy commissioner of Ontario, Canada, from 1997 to 2014. Cavoukian’s seven privacy by design principles emphasize the need for default and embedded privacy protections as online services became more complex and ubiquitous. The principles include transparency requirements about the collection of personal information for users and independent audits. By giving users easy control over privacy settings, Cavoukian aims for a “user-centric” approach to design that offers strong privacy by default. In 2010, an international conference of privacy regulators&nbsp;<a href="https://globalprivacyassembly.org/wp-content/uploads/2015/02/32-Conference-Israel-resolution-on-Privacy-by-Design.pdf" rel="noreferrer noopener" target="_blank">passed a resolution recognizing privacy by design</a>&nbsp;as an essential privacy protection, and in 2012 the&nbsp;<a href="https://www.ftc.gov/news-events/news/press-releases/2012/03/ftc-issues-final-commission-report-protecting-consumer-privacy" rel="noreferrer noopener" target="_blank">Federal Trade Commission recommended</a>&nbsp;the principles as a best practice for industry and that they be incorporated into law. Privacy by design was then incorporated as the foundation for the EU’s&nbsp;<a href="https://gdpr.eu/" rel="noreferrer noopener" target="_blank">General Data Protection Regulation</a>&nbsp;(GDPR) and similar legislation and regulation that followed around the world.&nbsp;&nbsp;</p>

<p data-widget="core/paragraph">Safety by design also builds upon “<a href="https://www.ncsc.gov.uk/collection/cyber-security-design-principles/cyber-security-design-principles" rel="noreferrer noopener" target="_blank">s</a><a href="https://www.ncsc.gov.uk/collection/cyber-security-design-principles/cyber-security-design-principles" rel="noreferrer noopener" target="_blank">ecurity by design</a>,” a set of cybersecurity guidelines for building and maintaining secure systems. This proactive organizational security approach is based on anticipating and guarding against the misuse of data or cyberattacks with principles that include regular monitoring, user verification, and limiting permissions to users who need access to specific systems and data. Safety by design similarly recognizes the potential for misuse and abuse of social tools and the need to proactively address and adapt to protect against that behavior.&nbsp;</p>

<p data-widget="core/paragraph">Together, privacy by design and security by design offer proactive tools for maintaining data security and privacy. While these earlier principles focus on digital architecture, such as databases and websites, safety by design addresses human interaction. Applying safety by design principles to social platforms requires that products are designed in the best interest of their users, setting safety and security defaults to the strongest option with transparency and control over recommendation and communication features. Under such a scheme, users would have the ability to adjust what they see, have personal information hidden by default, and have addictive features like autoplay videos turned off by default or be given reminders to take a break. Users would be prompted to review who sees what they share, who can contact them, or decide what data can be used for the ads and content that appear in their feeds and notifications—choices that could fundamentally change our online experiences.&nbsp;&nbsp;</p>

<p data-widget="core/paragraph">Beginning in 2018, Australia’s&nbsp;<a href="https://www.esafety.gov.au/industry/safety-by-design" rel="noreferrer noopener" target="_blank">eSafety Commissioner</a>&nbsp;<a href="https://www.esafety.gov.au/sites/default/files/2019-10/SBD%20-%20Overview%20May19.pdf" rel="noreferrer noopener" target="_blank">has worked</a>&nbsp;with industry and civil society and conducted research with parents and children to develop the first online&nbsp;<a href="https://www.esafety.gov.au/industry/safety-by-design" rel="noreferrer noopener" target="_blank">safety by design standards</a>. Its goal is to create technical standards that clearly guide developers and engineers at online services to improve a base level of online privacy and security. Particular attention has been placed on the&nbsp;<a href="https://www.ohchr.org/en/instruments-mechanisms/instruments/convention-rights-child" rel="noreferrer noopener" target="_blank">human rights of children</a>&nbsp;to address&nbsp;<a href="https://cyber.harvard.edu/pubrelease/isttf/" rel="noreferrer noopener" target="_blank">longstanding concerns</a>&nbsp;that children are uniquely exposed to bullying, sexual predators, and other potentially harmful experiences online.&nbsp;</p>

<h2 data-widget="core/heading">Safety by design in policy&nbsp;</h2>

<p data-widget="core/paragraph">Policymakers globally are beginning to integrate ideas drawing on safety by design concepts in legislation regulating online life. In the United States, for instance, proposals like the&nbsp;<a href="https://www.blumenthal.senate.gov/newsroom/press/release/blumenthal-and-blackburn-introduce-comprehensive-kids-online-safety-legislation" rel="noreferrer noopener" target="_blank">Kids Online Safety Act</a>&nbsp;(KOSA), the&nbsp;<a href="https://www.coons.senate.gov/news/press-releases/coons-portman-klobuchar-announce-legislation-to-ensure-transparency-at-social-media-platforms" rel="noreferrer noopener" target="_blank">Platform Accountability and Transparency Act</a>&nbsp;(PATA), and the&nbsp;<a href="https://trahan.house.gov/news/documentsingle.aspx?DocumentID=2389" rel="noreferrer noopener" target="_blank">Digital Services and Online Safety Act</a>&nbsp;(DSOSA) all have transparency and design requirements designed to give consumers and children control and understanding of their privacy and recommendation settings. In the EU, the&nbsp;<a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_22_4313" rel="noreferrer noopener" target="_blank">Digital Services Act</a>&nbsp;(DSA) was just approved by parliament and will require independent auditing, transparency reporting, data access for researchers, and risk assessments with corresponding design changes to recommendation algorithms and the user interface to mitigate potential harms. The U.K.’s&nbsp;<a href="https://bills.parliament.uk/bills/3137" rel="noreferrer noopener" target="_blank">Online Safety Bill</a>&nbsp;would require features that can filter out harmful content and control who can interact with content, set rules for transparency reporting, and mandate risk assessments on the safety and impact of design features.&nbsp;</p>

<p data-widget="core/paragraph">Here’s how each of these proposals would apply (or fail to apply) safety by design principles.&nbsp;</p>

<h2 data-widget="core/heading">Platform responsibility and accountability&nbsp;</h2>

<p data-widget="core/paragraph">Safety by design holds online platforms and services responsible for the safety of users by assessing, addressing, and mitigating potential harms before they occur. Policy measures require platforms to study the impact of their design and algorithmic recommendations and make the findings available for audit, forcing accountability and incentivizing platforms to embed features that are designed to improve the wellbeing of users. Internal risk assessments and independent audits are a common feature of safety by design policy proposals, including the U.S. Senate’s KOSA, the House’s DSOSA, the EU’s DSA, and the U.K. Online Safety Bill. While the U.K. relies on a&nbsp;<a href="https://www.ofcom.org.uk/home" rel="noreferrer noopener" target="_blank">communications regulator</a>&nbsp;to conduct the audits, the EU and U.S. put audit responsibilities in the hands of third-party organizations—something major consulting firms are&nbsp;<a href="https://www2.deloitte.com/uk/en/blog/auditandassurance/2022/eu-digital-services-act-are-you-ready-for-audit.html" rel="noreferrer noopener" target="_blank">already preparing for</a>.&nbsp;&nbsp;</p>

<p data-widget="core/paragraph">European and American legislative proposals develop a combination of internal risk assessment and independent auditing requirements with public transparency reports that would give greater insight into how platforms operate. In the DSA, the largest social platforms are required to conduct risk assessments and submit to independent audits that examine systemic risks and assess overall compliance in a report submitted to regulators. Auditors have broad purview to assess obligations including transparency reporting and data sharing while also gaining access to review algorithms used to curate posts and target advertising. Similar provisions are included in the U.S. House’s DSOSA proposal covering recommendation systems, while the Senate’s KOSA proposal makes some auditing and risk mitigation findings public, including outlines of identified risks and how personal data may be used in recommendation systems and other algorithms. In the U.K., platforms will also have a duty of care for algorithms and design functionalities. The Online Safety Bill risk assessments cover the removal of illegal content and broadly assess unique harms for children and for adults from the design and functions of a service and how they might be misused. Proactive safety measures are also a key component of the proposals. Most notably, targeted advertising would be banned or partially banned for children in EU and U.S. proposals, while the U.K. legislation forbids “fraudulent advertising.”&nbsp;&nbsp;</p>

<h2 data-widget="core/heading">Design to empower users&nbsp;</h2>

<p data-widget="core/paragraph">A recent&nbsp;<a href="https://knightfoundation.org/reports/media-and-democracy/" rel="noreferrer noopener" target="_blank">Gallup and Knight Foundation report</a>&nbsp;found that while users don’t agree on how much responsibility government or social media companies have to moderate content, most want more choice and control over their own experience. While&nbsp;<a href="https://www.theguardian.com/media/2022/jun/27/young-people-must-report-harmful-online-content-says-uk-watchdog" rel="noreferrer noopener" target="_blank">two-thirds of children</a>&nbsp;in the U.K. say they have experienced online harassment or predatory behavior, less than 20% report that abuse. And it’s not just children: Nearly two-thirds of adults under age 30 say they have&nbsp;<a href="https://www.pewresearch.org/internet/2021/01/13/the-state-of-online-harassment/" rel="noreferrer noopener" target="_blank">experienced online harassment</a>. Giving users the ability to control who can message them and limit what content they see online would provide more privacy and protections for all vulnerable groups.&nbsp;</p>

<p data-widget="core/paragraph">In the United States, KOSA would begin to address the desire for greater user control by mandating design features that prevent contact from strangers, hiding personal information by default, limiting features that reward more time spent on a platform, and allowing users to opt out of algorithmic recommendations based on personal data. However, these design requirements would be limited to children 16 and younger and mainly facilitated by parental control tools. The U.K. has a similar provision giving users controls over who can interact with the content they share. In California, the&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202120220AB2408" rel="noreferrer noopener" target="_blank">Social Media Platform Duty to Children Act</a>&nbsp;would prohibit design features known to cause addiction. The California Age-Appropriate Design Code Act also has design requirements for minors but focuses more on privacy protections “by design and by default,” with broad mandates to prioritize the wellbeing of children when designing online services and features.&nbsp;&nbsp;</p>

<p data-widget="core/paragraph">The EU and U.K. proposals focus more on content moderation, requiring extensive systems for reporting content users deem harmful, including a provision in the Digital Services Act for “<a href="https://www.lexology.com/library/detail.aspx?g=0045b1bf-165b-4ee9-93a9-011cf8b796d4" rel="noreferrer noopener" target="_blank">trusted flaggers</a>,” which are independent organizations with expertise in a specific type of harm that are given priority processing. Both regimes include risk assessment and mitigation components. The DSA also requires the largest social media platforms to allow users to select a feed option that does not use personal data to recommend content.&nbsp;</p>

<p data-widget="core/paragraph">A stark divide exists between the United States and Europe in their approaches to design rules aimed at empowering users. While the DSA and Online Safety Bill apply at least some design rules for all users with special protections for minors, the U.S. proposals apply exclusively to children, offering parents greater control over the content their children consume.&nbsp;</p>

<h2 data-widget="core/heading">Transparency and researcher access&nbsp;</h2>

<p data-widget="core/paragraph">In order to understand the functioning of algorithmic recommendation systems, researchers and policymakers currently rely on the goodwill of platforms to furnish data and on whistleblowers to supply internal company documents. Addressing this gap and providing greater access for researchers to company data is a key component of the DSA and U.S. proposals but is absent in the U.K. Online Safety Bill, which only requires further study of the matter. U.S. proposals, including KOSA and PATA, also include protections for independent researchers who develop their own means for data collection and analysis. The DSA and U.S. legislation would set up government organizations with subject matter experts who vet researchers and mediate data access and sharing with platforms. Other transparency requirements include reports on public content and aggregate engagement information, libraries to search and review advertising, and public reports that outline findings from risk assessments and independent audits.&nbsp;&nbsp;</p>

<h2 data-widget="core/heading">Setting the foundation&nbsp;</h2>

<p data-widget="core/paragraph">Safety by design proposals hold promise but are not without potential pitfalls. Developing technical protocols and future-proofing rules will be crucial for policy and regulations to have the intended effects of protecting consumers while fostering innovation and free speech online. Developing rules that only protect children would be a missed opportunity to empower all consumers to make individual decisions about their wellbeing online. This broader approach would importantly provide vulnerable and minority groups tools to protect against harmful content and conduct.&nbsp;</p>

<p data-widget="core/paragraph">Transparency and researcher access provisions must have protections for potential security risks in sharing data, and any public reporting should take precautions to protect user privacy and avoid de-anonymization. These considerations and technical protocols are being worked out with&nbsp;<a href="https://edmo.eu/2022/05/31/edmo-releases-report-on-researcher-access-to-platform-data/" rel="noreferrer noopener" target="_blank">industry and civil society input</a>&nbsp;to implement the Digital Services Act and could be further refined to fit U.S. privacy expectations and regulatory systems.&nbsp;<a href="https://www.lawfareblog.com/platform-transparency-legislation-whos-whats-and-hows" rel="noreferrer noopener" target="_blank">Proposals already exist</a>&nbsp;for sharing advertising and high-reach content while protecting user privacy.&nbsp;</p>

<p data-widget="core/paragraph">The internet is global and we should not be reinventing the wheel to develop best practices and interoperability for data sharing and security controls. Consistency would allow more countries to adopt rules built on safety by design principles, companies to navigate a more streamlined patchwork of regulation, and promote competition by allowing smaller platforms and emerging competitors to more easily comply as they scale operations. Consistency does not mean copying the same regulation around the world, but rather applying the same technical protocols and best practices across unique rules, for instance those that preserve First Amendment protections online in the U.S.&nbsp;</p>

<p data-widget="core/paragraph">Clear, but flexible definitions are needed in safety by design rules and guidelines as more companies develop platforms for interacting in virtual spaces and as video games grow increasingly social. Standards should be relevant and forward-looking to cover unique services and the safe development of new platforms, such as addressing control and protections for live interactions in virtual environments—not just rules for text or media content. If annual audits address business model incentives, they can help future-proof these rules and continue to educate policymakers and the public on how platforms operate. There should also be rules to continue to assess and update definitions for covered platforms as technologies change.&nbsp;</p>

<p data-widget="core/paragraph">Special duties to protect children make sense for unique vulnerabilities such as exposure to mature content, sexual grooming or online bullying and harassment. However, age verification requirements should be minimal and rules should generally provide protections and empower all users. Age verification and parental tools, while well-intentioned, have the potential to increase risk for minors with systems that only track young users. Verifying parents and guardians for access to parental controls will also require safety mechanisms to protect children’s privacy and avoid exploitation from bad actors with access to such tools. It would be better to provide greater protections to all users than to only offer heightened safety features for children who may attempt to sidestep those controls.&nbsp;</p>

<p data-widget="core/paragraph">By providing users with greater control over their experiences online, safety by design can reduce harms in online spaces while protecting free speech. While getting the details right for a regulatory regime that incorporates safety by design principles will be difficult and important, it’s time for policy solutions that address the features and incentives in digital platforms that promote and spread real-life harms.&nbsp;</p>
</div>
      
</div>
</div>
</div>
              <div class="paragraph-item ptype-read-more">

<div class="read-more">
  
<div  class="read-more pt-10 pb-2.5 768:pt-12.5 768:pb-5 1024:pt-[90px] 1024:pb-[70px] bg-[#ffffff]" >
  <div class="container">
          

<h3
   class="h h--gleam text-center h3"
>Read More</h3>
    
    <div  class="read-more__items read-more__items--3-items 768:flex 768:justify-center" >
                                    

<div  about="/io/self-harm-policies-report" class="news-teaser news-teaser--card px-7.5 pb-4.5 relative bg-white" >
      <div  class="news-teaser__img news-teaser__img--card -mx-7.5 mb-5" >
        
            <div class="node news field-teaser-image entity-reference label-hidden">
  
              

  
<picture
   loading="eager" class="image"
>
          <!--[if IE 9]><video style="display: none;"><![endif]-->
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/375x211/public/hero/suicide-prevention-headliner.png?h=3490838a&amp;itok=CAxFb4dQ 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/375x211_x2/public/hero/suicide-prevention-headliner.png?h=3490838a&amp;itok=HbZPjdRy 2x" media="all and (min-width: 768px)" type="image/png" width="375" height="211"/>
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409/public/hero/suicide-prevention-headliner.png?h=3490838a&amp;itok=DQ2OVrCF 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409_x2/public/hero/suicide-prevention-headliner.png?h=3490838a&amp;itok=cyW8LnnH 2x" media="all and (max-width: 767px)" type="image/png" width="727" height="409"/>
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/440x245/public/hero/suicide-prevention-headliner.png?h=3490838a&amp;itok=2wbWvFHo 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/440x245_x2/public/hero/suicide-prevention-headliner.png?h=3490838a&amp;itok=DPEtY3nk 2x" media="all and (max-width: 480px)" type="image/png" width="440" height="245"/>
        <!--[if IE 9]></video><![endif]-->
      
<img
   class="image"
      src="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409/public/hero/suicide-prevention-headliner.png?h=3490838a&amp;itok=DQ2OVrCF"
      alt="clipart-suicide-support"
    />
</picture>


      
</div>
      
    </div>
        <div  class="news-teaser__type mb-6 text-20 text-red" >
      Blogs
    </div>
        

<h2
   class="h h--small h2"
>Sizing Up Self-Harm Policies</h2>
        <div  class="news-teaser__description mb-4 480m:text-16" >
      The Stanford Internet Observatory’s latest report compares online platforms’ policies on self-harm content.
    </div>
                  
<a
   class="link link--cover"
    href="/io/self-harm-policies-report"
>
  cover link
      Sizing Up Self-Harm Policies
  </a>
  </div>

                                        

<div  about="/io/news/reddit-hate-speech" class="news-teaser news-teaser--card px-7.5 pb-4.5 relative bg-white" >
      <div  class="news-teaser__img news-teaser__img--card -mx-7.5 mb-5" >
        
            <div class="node news field-teaser-image entity-reference label-hidden">
  
              

  
<picture
   loading="eager" class="image"
>
          <!--[if IE 9]><video style="display: none;"><![endif]-->
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/375x211/public/hero/reddit_hate_speech.png?h=00546c34&amp;itok=bAyPsYTT 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/375x211_x2/public/hero/reddit_hate_speech.png?h=00546c34&amp;itok=uuycz4cu 2x" media="all and (min-width: 768px)" type="image/png" width="375" height="211"/>
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409/public/hero/reddit_hate_speech.png?h=00546c34&amp;itok=FTfADJmS 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409_x2/public/hero/reddit_hate_speech.png?h=00546c34&amp;itok=7DjSYoCQ 2x" media="all and (max-width: 767px)" type="image/png" width="727" height="409"/>
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/440x245/public/hero/reddit_hate_speech.png?h=00546c34&amp;itok=6HAOBSCN 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/440x245_x2/public/hero/reddit_hate_speech.png?h=00546c34&amp;itok=2-EyERCT 2x" media="all and (max-width: 480px)" type="image/png" width="440" height="245"/>
        <!--[if IE 9]></video><![endif]-->
      
<img
   class="image"
      src="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409/public/hero/reddit_hate_speech.png?h=00546c34&amp;itok=FTfADJmS"
      alt="reddit hate speech"
    />
</picture>


      
</div>
      
    </div>
        <div  class="news-teaser__type mb-6 text-20 text-red" >
      Blogs
    </div>
        

<h2
   class="h h--small h2"
>Comparing Platform Hate Speech Policies: Reddit's Inevitable Evolution</h2>
        <div  class="news-teaser__description mb-4 480m:text-16" >
      On Monday, June 30, 2020, Reddit updated its policy on hate speech. As part of research for a forthcoming book based on the Stanford Internet Observatory’s Trust and Safety Engineering course, we present a comparative assessment of platform policies and enforcement practices on hate speech, and discuss how Reddit fits into this framework.
    </div>
                  
<a
   class="link link--cover"
    href="/io/news/reddit-hate-speech"
>
  cover link
      Comparing Platform Hate Speech Policies: Reddit&#039;s Inevitable Evolution
  </a>
  </div>

                                        

<div  about="/io/news/why-encryption-and-online-safety-go-hand-hand" class="news-teaser news-teaser--card px-7.5 pb-4.5 relative bg-white" >
      <div  class="news-teaser__img news-teaser__img--card -mx-7.5 mb-5" >
        
            <div class="node news field-hero-image entity-reference label-hidden">
  
              

  
<picture
   loading="eager" class="image"
>
          <!--[if IE 9]><video style="display: none;"><![endif]-->
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/375x211/public/hero/image_of_cursor_hovering_over_word.jpeg?h=b228cdea&amp;itok=01T8eBYM 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/375x211_x2/public/hero/image_of_cursor_hovering_over_word.jpeg?h=b228cdea&amp;itok=l5ffL7Vb 2x" media="all and (min-width: 768px)" type="image/jpeg" width="375" height="211"/>
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409/public/hero/image_of_cursor_hovering_over_word.jpeg?h=b228cdea&amp;itok=ke_Mtvcw 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409_x2/public/hero/image_of_cursor_hovering_over_word.jpeg?h=b228cdea&amp;itok=WkBEP_fs 2x" media="all and (max-width: 767px)" type="image/jpeg" width="727" height="409"/>
          <source srcset="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/440x245/public/hero/image_of_cursor_hovering_over_word.jpeg?h=b228cdea&amp;itok=-CgbWAn1 1x, https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/440x245_x2/public/hero/image_of_cursor_hovering_over_word.jpeg?h=b228cdea&amp;itok=XinOSxUK 2x" media="all and (max-width: 480px)" type="image/jpeg" width="440" height="245"/>
        <!--[if IE 9]></video><![endif]-->
      
<img
   class="image"
      src="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/styles/727x409/public/hero/image_of_cursor_hovering_over_word.jpeg?h=b228cdea&amp;itok=ke_Mtvcw"
      alt="image of cursor hovering over an image of a lock"
    />
</picture>


      
</div>
      
    </div>
        <div  class="news-teaser__type mb-6 text-20 text-red" >
      Blogs
    </div>
        

<h2
   class="h h--small h2"
>Why Encryption and Online Safety Go Hand-in-Hand</h2>
        <div  class="news-teaser__description mb-4 480m:text-16" >
      Riana Pfefferkorn is a research scholar at the Stanford Internet Observatory and a member of the Global Encryption Coalition. This first appeared in Brookings TECH STREAM.
    </div>
                  
<a
   class="link link--cover"
    href="/io/news/why-encryption-and-online-safety-go-hand-hand"
>
  cover link
      Why Encryption and Online Safety Go Hand-in-Hand
  </a>
  </div>

                            </div>
  </div>
</div>
</div>
</div>
          </div>
  

          <div class="container text-center py-4 1024:py-5">
    
<a
   class="link link--btn"
    href="http://cyber.fsi.stanford.edu/io/news"
>
  
      All Internet Observatory News
  </a>
</div>
      </div>
</article>

  </div>

  </div>

    </main>
  </div>
      <footer>
              <div  class="footer__social region region-footer-social">
  <div class="container flex items-center justify-center 768:justify-between py-4">
          <div  id="block-fsi-center-logo" class="block fsi-center-logo">
  
    
        <a href="/io" rel="home">
      <img src="https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/2022-09/internet-observatory-web_-_tara_c_wright.jpg" alt="IO Logo"/>
    </a>
  </div>

      </div>
</div>

      
              
<section  class="footer__center region region-footer-center">
  <div class="
    container
    flex flex-wrap 768:flex-nowrap
    pt-9 pb-7.5
  ">
          <div  id="block-footer-contact-us" class="block block-content _0723fba-76bd-4764-8856-dabdde04e703">
  
    
      

            <div class="block-content basic body text-with-summary label-hidden text-long"><h3 class="footer-panel__title">Our Address</h3>

<div class="logo-footer"><a href="https://fsi.stanford.edu"><img alt="Stanford University" height="52" src="/themes/custom/stanford_fsi/images/logo-white.png" width="517" loading="lazy"> </a></div>

<div class="footer-panel__body">Encina Hall<br>
616 Jane Stanford Way<br>
Stanford University<br>
Stanford, CA 94305-6055</div>
</div>
      
  </div>
<div  id="block-footer-menu" class="menu-block footer block block-menu navigation menu--footer">
      
  <h2 id="menu-blockfooter-menu">Navigate</h2>
  

        


    
                          
    
<ul  class="menu">
            
<li  class="menu__item">
                <a href="https://fsi.stanford.edu/research" class="menu__link">Research</a>
          </li>
          
<li  class="menu__item">
                <a href="https://fsi.stanford.edu/education" class="menu__link">Education</a>
          </li>
          
<li  class="menu__item">
                <a href="https://fsi.stanford.edu/policy" class="menu__link">Policy</a>
          </li>
          
<li  class="menu__item">
                <a href="https://fsi.stanford.edu/people/institute-faculty" class="menu__link">People</a>
          </li>
          
<li  class="menu__item">
                <a href="https://fsi.stanford.edu/centers" class="menu__link">Centers</a>
          </li>
          
<li  class="menu__item">
                <a href="https://fsi.stanford.edu/news" class="menu__link">News</a>
          </li>
          
<li  class="menu__item">
                <a href="https://fsi.stanford.edu/events" class="menu__link">Events</a>
          </li>
          
<li  class="menu__item">
                <a href="https://fsi.stanford.edu/about" class="menu__link">About</a>
          </li>
      </ul>
  

  </div>
<div  id="block-footer-follow-us" class="block block-content _c2785de-22f2-473e-bc20-d8b2d9c45b38">
  
    
      

            <div class="block-content basic body text-with-summary label-hidden text-long"><h3 class="footer-panel__title">Follow Us</h3><p><strong>General inquiries</strong><br>650-723-4581</p><ul class="social-menu"><li class="social-menu__item"><a class="social-menu__link social-menu__link--mail" href="https://fsi.stanford.edu/content/get-connected" target="_blank">Mail</a></li><li class="social-menu__item"><a class="social-menu__link social-menu__link--twitter" href="https://twitter.com/FSIStanford" target="_blank">Twitter</a></li><li class="social-menu__item"><a class="social-menu__link social-menu__link--facebook" href="https://www.facebook.com/StanfordFSI" target="_blank">Facebook</a></li><li class="social-menu__item"><a class="social-menu__link social-menu__link--youtube" href="https://www.youtube.com/channel/UCB2X9yR4GZLfrCe4jChIEwg" target="_blank">Youtube</a></li><li class="social-menu__item"><a class="social-menu__link social-menu__link--instagram" href="https://www.instagram.com/fsi_stanford" target="_blank">Instagram</a></li><li class="social-menu__item"><a class="social-menu__link social-menu__link--linkedin" href="https://www.linkedin.com/company/freeman-spogli-institute-for-international-studies" target="_blank">LinkedIn</a></li><li class="social-menu__item"><a class="social-menu__link social-menu__link--threads" href="https://www.threads.net/@fsi_stanford" target="_blank">Threads</a></li></ul></div>
      
  </div>
<div  id="block-footer-support-us" class="block block-content f442c8ab-1101-42e7-960d-79b4d0701c1c">
  
    
      

            <div class="block-content basic body text-with-summary label-hidden text-long"><h3 class="footer-panel__title">Support Us</h3>

<div class="support-us">
<p>Learn more about how your support makes a difference or make a gift now</p>
<a class="link link--btn link--yellow" href="https://fsi.stanford.edu/supporting-fsi">Make a gift</a></div>
</div>
      
  </div>

      </div>
</section>

      
      
              <div class="back-top 768:hidden text-center py-5">
  <span class="back-top__icon"></span>
  <a href="#main-content" class="back-top__link">Top</a>
</div>

<div
   class="footer__copyright region region-footer-copyrights"
  role="contentinfo"
>
  <div class="container flex flex-wrap py-5 justify-center relative 768:pt-7 768:pb-8.5">
    <div  class="footer__copyright-logo mb-4.5 w-full">
      <img src="/themes/custom/stanford_fsi/images/footer-stanford-logo.png" class="w-[112px] m-auto 768:w-[120px]" alt="Footer logo">
    </div>
          <div  id="block-footer-stanford-menu" class="menu-block footer-stanford block block-menu navigation menu--footer-stanford">
            
  <h2 class="visually-hidden" id="menu-blockfooter-stanford-menu">Footer Stanford Menu</h2>
  

        


    
                          
    
<ul  class="menu">
            
<li  class="menu__item">
                <a href="https://www.stanford.edu/" class="menu__link">Stanford Home</a>
          </li>
          
<li  class="menu__item">
                <a href="https://visit.stanford.edu/plan/" class="menu__link">Maps &amp; Directions</a>
          </li>
          
<li  class="menu__item">
                <a href="https://www.stanford.edu/search/" class="menu__link">Search Stanford</a>
          </li>
          
<li  class="menu__item">
                <a href="https://emergency.stanford.edu/" class="menu__link">Emergency Info</a>
          </li>
      </ul>
  

  </div>
<div  id="block-footer-terms-menu" class="menu-block footer-terms block block-menu navigation menu--footer-terms">
            
  <h2 class="visually-hidden" id="menu-blockfooter-terms-menu">Footer Terms Menu</h2>
  

        


    
                          
    
<ul  class="menu">
            
<li  class="menu__item">
                <a href="https://www.stanford.edu/site/terms/" class="menu__link">Terms of Use</a>
          </li>
          
<li  class="menu__item">
                <a href="https://www.stanford.edu/site/privacy/" class="menu__link">Privacy</a>
          </li>
          
<li  class="menu__item">
                <a href="https://uit.stanford.edu/security/copyright-infringement" class="menu__link">Copyright</a>
          </li>
          
<li  class="menu__item">
                <a href="https://adminguide.stanford.edu/chapter-1/subchapter-5/policy-1-5-4" class="menu__link">Trademarks</a>
          </li>
          
<li  class="menu__item">
                <a href="http://exploredegrees.stanford.edu/nonacademicregulations/nondiscrimination/" class="menu__link">Non-Discrimination</a>
          </li>
          
<li  class="menu__item">
                <a href="https://www.stanford.edu/site/accessibility/" class="menu__link">Accessibility</a>
          </li>
          
<li  class="menu__item">
                <a href="https://uit.stanford.edu/security/copyright-infringement" class="menu__link">Copyright Complaints</a>
          </li>
      </ul>
  

  </div>
<div  id="block-copyright-content" class="block block-content e1315f88-6342-4fdd-98de-4aed8bcf8e4b">
  
    
      

            <div class="block-content basic body text-with-summary label-hidden text-long"><div class="footer-global__copyright">
<p class="vcard">© <span class="fn org">Stanford University</span>, <span class="adr"><span class="locality">Stanford</span>, <span class="region">California</span> <span class="postal-code">94305</span></span>.</p>
</div>
</div>
      
  </div>

      </div>
</div>

          </footer>
  </div>

  </div>


<script src="/sites/default/files/js/js_Tk2om-1g0i9LtNb7ff-ZXSNkKcfj5i3zeiSGnXEFt7o.js?scope=footer&amp;delta=0&amp;language=en&amp;theme=stanford_fsi&amp;include=eJxdjksOg0AMQy8EneN0iQyETMp8UBKqHr-oiErDJnq2pdjmKEvVeRhhMoXf7ewyF5PAqY5IHdfKiQYHB_bcSvBdP_DCp7MIJY9i4U_tb-weq1qfxLxNbFNxar1ImEl7r3xUtVGmsvcZUq4hk1E48aAnnDRD11vHKlvB-ws1DGU2"></script>
<script src="https://ws.sharethis.com/button/buttons.js"></script>
<script src="/sites/default/files/js/js_iR7qCnmX0DSAr6C2-WN2xC5Ax94qPs5ASdO_r1BxFUw.js?scope=footer&amp;delta=2&amp;language=en&amp;theme=stanford_fsi&amp;include=eJxdjksOg0AMQy8EneN0iQyETMp8UBKqHr-oiErDJnq2pdjmKEvVeRhhMoXf7ewyF5PAqY5IHdfKiQYHB_bcSvBdP_DCp7MIJY9i4U_tb-weq1qfxLxNbFNxar1ImEl7r3xUtVGmsvcZUq4hk1E48aAnnDRD11vHKlvB-ws1DGU2"></script>
<script src="/themes/custom/stanford_fsi/components/01-atoms/images/icons/svgxuse.min.js?sqgpes" defer></script>
<script src="/sites/default/files/js/js_q8nFoQqm43AOfB7jwMRCgI0_PSjymbsH1ldDt87PVW0.js?scope=footer&amp;delta=4&amp;language=en&amp;theme=stanford_fsi&amp;include=eJxdjksOg0AMQy8EneN0iQyETMp8UBKqHr-oiErDJnq2pdjmKEvVeRhhMoXf7ewyF5PAqY5IHdfKiQYHB_bcSvBdP_DCp7MIJY9i4U_tb-weq1qfxLxNbFNxar1ImEl7r3xUtVGmsvcZUq4hk1E48aAnnDRD11vHKlvB-ws1DGU2"></script>

</body>
</html>
